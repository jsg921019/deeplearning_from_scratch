{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 완전계층 (Affine 계층)은 2차원 이상의 데이터를 flatten하기 때문에 데이터의 공간적 정보가 무시됨\n",
    "* CNN은 형상을 유지하기 때문에 이러한 정보를 살릴 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ⅰ. 합성곱 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Kernel (Filter)\n",
    "\n",
    "* Fully connected layer에서의 가중치 역할과 유사하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../img/fig 7-3.png' width=50%, height=50%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../img/fig 7-4.png' width=50%, height=50%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bias\n",
    "\n",
    "* Fully connected layer에서의 bias 역할과 유사하다\n",
    "* bias를 부여하는 방식은 2가지가 있음\n",
    "  * Tied bias: 각 출력 특성맵 당 하나의 bias, 즉 한 특성맵의 모든 픽셀에서 bias는 동일하다 <= 일반적으로 이 방식을 쓴다\n",
    "  * Untied bias: 각 출력 특성맵의 픽셀 당 하나의 bias\n",
    "\n",
    "<img src='../img/fig 7-5.png' width=70%, height=70%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 합성곱 연산을 수행하기 전에 입력 데이터 주변을 특정 값으로(보통 0)으로 채우는 것\n",
    "* 쓰는 이유\n",
    "  * 출력 크기 조정\n",
    "  * 테두리 정보 보존"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../img/fig 7-6.png' width=50%, height=50%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 필터를 적용하는 위치의 간격"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../img/fig 7-7.png' width=50% height=50%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 관계식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{input dimension} = (h_i, w_i) \\quad \\text{kernel size} = (h_k, w_k) \\quad \\text{padding} = (p_h, p_w) \\quad \\text{stride} = (s_h, s_w) \\quad \\text{일때,} \\\\\n",
    "$$\n",
    "</br>\n",
    "$$\n",
    "\\text{output dimension} \\; (h_o, w_o) = ( \\frac{h_i + 2p_h - h_k}{s_h} + 1, \\frac{w_i + 2p_w - w_k}{s_w} + 1 )\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 3차원 데이터에서의 합성곱 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2차원 이미지가 여러 채널 있는 경우\n",
    "* 입력 이미지의 채널 수 만큼 커널의 채널이 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../img/fig 7-8.png' width=50% height=50%/>\n",
    "<img src='../img/fig 7-9.png' width=50% height=50%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 블록으로 표현하면 다음과 같이 나타낼 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../img/fig 7-10.png' width=50% height=50%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 여러개의 특성 맵을 얻고자 하면 여러개의 커널을 사용하면 됨(Fully connected layer와 같다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../img/fig 7-13.png' width=70% height=70%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 계산의 편리성을 위해 im2col함수를 사용 (대신 겹치는 영역때문에 메모리가 더 요구됨)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../img/fig 7-19.png' width=70% height=70%/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data, in_channel, out_h, out_w, filter_h, filter_w, stride=1, pad=0):\n",
    "    '''\n",
    "    순전파 계산시에 사용\n",
    "    '''\n",
    "\n",
    "    input_data = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    stack = [input_data[:,:,i:i + stride*out_h:stride,j:j + stride*out_w:stride] \n",
    "             for i in range(filter_h) for j in range(filter_w)]\n",
    "    col = np.stack(stack).transpose((1,3,4,2,0)).reshape(-1, filter_h * filter_w * in_channel)\n",
    "\n",
    "    return col\n",
    "\n",
    "def col2im(col, input_shape, out_h, out_w, filter_h, filter_w, stride=1, pad=0):\n",
    "    '''\n",
    "    역전파 계산시에 사용\n",
    "    '''\n",
    "\n",
    "    n, in_channel, in_h, in_w = input_shape\n",
    "\n",
    "    col = col.reshape(n, out_h, out_w, in_channel, filter_h, filter_w).transpose(0, 3, 1, 2, 4, 5)\n",
    "    img = np.zeros((n, in_channel, in_h + 2*pad, in_w + 2*pad))\n",
    "    \n",
    "    for i in range(filter_h):\n",
    "        for j in range(filter_w):\n",
    "            img[..., i:i+stride*out_h:stride, j:j+stride*out_w:stride] += col[..., i, j]\n",
    "\n",
    "    return img[..., pad:in_h + pad, pad:in_w + pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, stride=1, padding=0, W=None, b=None):\n",
    "\n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "\n",
    "        self.kernel_h, self.kernel_w = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        \n",
    "        self.input_shape = None\n",
    "        self.col = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        n, _, in_h, in_w = x.shape\n",
    "\n",
    "        out_h = 1 + (in_h + 2*self.padding - self.kernel_h) // self.stride\n",
    "        out_w = 1 + (in_w + 2*self.padding - self.kernel_w) // self.stride\n",
    "\n",
    "        col = im2col(x, self.in_channel, out_h, out_w, self.kernel_h, self.kernel_w, self.stride, self.padding)\n",
    "        out = np.dot(col, self.W) + self.b\n",
    "        out = out.reshape(-1, out_h, out_w, self.out_channel).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.input_shape = x.shape\n",
    "        self.col = col\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "\n",
    "        n, _, out_h, out_w = dout.shape\n",
    "        \n",
    "        dout = dout.transpose(0,2,3,1).reshape(-1, self.out_channel)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dW = np.dot(self.col.T, dout)\n",
    "        dcol = np.dot(dout, self.W.T)\n",
    "        dx = col2im(dcol, self.input_shape, out_h, out_w, self.kernel_h, self.kernel_w, self.stride, self.padding)\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ⅱ. Pooling Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 영역을 집약하여 공간을 줄이는 연산\n",
    "  * max pooling : 최댓값을 집약 <= 일반적으로 쓰는 pooling\n",
    "  * mean pooling : 평균값으로 집약\n",
    "* 학습해야할 매개변수가 없음\n",
    "\n",
    "<img src='../img/fig 7-14.png' width=50% height=50%/>\n",
    "\n",
    "* 입력의 변화에 영향을 적게 받음\n",
    "<img src='../img/fig 7-16.png' width=50% height=50%/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "\n",
    "    def __init__(self, pool_h, pool_w, stride=1, padding=0):\n",
    "\n",
    "        self.pool_h, self.pool_w = pool_h, pool_w\n",
    "        self.stride, self.padding = stride, padding\n",
    "        \n",
    "        self.max_idx = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        self.input_shape = x.shape\n",
    "        n, in_channel, in_h, in_w = x.shape\n",
    "        \n",
    "        out_h = 1 + (in_h + 2*self.padding - self.pool_h) // self.stride\n",
    "        out_w = 1 + (in_w + 2*self.padding - self.pool_w) // self.stride\n",
    "\n",
    "        col = im2col(x, in_channel, out_h, out_w, self.pool_h, self.pool_w, self.stride, self.padding)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "\n",
    "        self.max_idx = np.argmax(col, axis=1)\n",
    "        out = np.max(col, axis=1)\n",
    "        out = out.reshape(n, out_h, out_w, in_channel).transpose(0,3,1,2)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        \n",
    "        n, in_channel, out_h, out_w = dout.shape\n",
    "        dcol = dout.transpose(0,2,3,1).reshape(-1,1)\n",
    "\n",
    "        eye = np.eye(self.pool_h * self.pool_w)\n",
    "        dcol = dcol * eye[self.max_idx]\n",
    "        dcol = dcol.reshape(-1, self.pool_h*self.pool_w*in_channel)\n",
    "\n",
    "        dx = col2im(dcol, self.input_shape, out_h, out_w, self.pool_h, self.pool_w, self.stride, self.padding)\n",
    "\n",
    "        return dx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
